{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257834f3",
   "metadata": {},
   "source": [
    "\n",
    "# Bellabeat Smart Device Market Analysis â€” Notebook\n",
    "\n",
    "This notebook mirrors the project steps from the PDF and repo scripts. It focuses on **runnable, text-based EDA** (no charts) and shows how to generate the merged daily dataset and sanity-check it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f171fb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 120)\n",
    "print('Pandas version:', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d06014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/seunghyunhong/simonhong/Projects/bellabeat-analysis\n",
      "Data dir : /Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths (run this cell from notebooks/)\n",
    "REPO_ROOT = Path('..').resolve()\n",
    "DATA_DIR = (REPO_ROOT / 'data').resolve()\n",
    "print('Repo root:', REPO_ROOT)\n",
    "print('Data dir :', DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424eb9cf",
   "metadata": {},
   "source": [
    "\n",
    "## Generate cleaned daily dataset\n",
    "\n",
    "This calls the Python ETL script to create `data/daily_merged.csv` with derived metrics: `TotalActiveMinutes` and `SleepEfficiency`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233591a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python /Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/scripts/analysis.py --data_dir /Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/data --out_dir /Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/data\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/scripts/analysis.py\"\u001b[0m, line \u001b[35m85\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m(args.data_dir, args.out_dir)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/seunghyunhong/simonhong/Projects/bellabeat-analysis/scripts/analysis.py\"\u001b[0m, line \u001b[35m24\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise FileNotFoundError('No daily activity CSVs found in data/. Expected e.g. dailyActivity_merged.csv')\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35mNo daily activity CSVs found in data/. Expected e.g. dailyActivity_merged.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, subprocess, shlex\n",
    "script = REPO_ROOT / 'scripts' / 'analysis.py'\n",
    "cmd = f\"python {script} --data_dir {DATA_DIR} --out_dir {DATA_DIR}\"\n",
    "print('Running:', cmd)\n",
    "completed = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "print(completed.stdout)\n",
    "print(completed.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc7db0",
   "metadata": {},
   "source": [
    "\n",
    "## Load and sanity-check `daily_merged.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812b0a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "daily_merged.csv was not found. Ensure Kaggle CSVs are in data/ and re-run the ETL cell.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df = pd.read_csv(merged_path) \u001b[38;5;28;01mif\u001b[39;00m merged_path.exists() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mdaily_merged.csv was not found. Ensure Kaggle CSVs are in data/ and re-run the ETL cell.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.shape)\n\u001b[32m      6\u001b[39m df.head()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: daily_merged.csv was not found. Ensure Kaggle CSVs are in data/ and re-run the ETL cell."
     ]
    }
   ],
   "source": [
    "\n",
    "merged_path = DATA_DIR / 'daily_merged.csv'\n",
    "df = pd.read_csv(merged_path) if merged_path.exists() else None\n",
    "if df is None:\n",
    "    raise FileNotFoundError('daily_merged.csv was not found. Ensure Kaggle CSVs are in data/ and re-run the ETL cell.')\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a868d5",
   "metadata": {},
   "source": [
    "\n",
    "## Text-based EDA (no charts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90010fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Null counts\n",
    "nulls = df.isna().sum().sort_values(ascending=False)\n",
    "print('Top nulls:')\n",
    "print(nulls.head(10))\n",
    "\n",
    "# Describe key columns\n",
    "cols = [c for c in ['TotalSteps','Calories','VeryActiveMinutes','FairlyActiveMinutes','LightlyActiveMinutes','SedentaryMinutes','TotalMinutesAsleep','TotalTimeInBed','TotalActiveMinutes','SleepEfficiency'] if c in df.columns]\n",
    "df[cols].describe(percentiles=[.25,.5,.75])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74d701",
   "metadata": {},
   "source": [
    "\n",
    "## Segmentations\n",
    "Activity level buckets (by steps) and sleep adequacy buckets mirroring the SQL snippets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bucket_activity(steps):\n",
    "    if pd.isna(steps): return 'Unknown'\n",
    "    if steps >= 12500: return 'High Active'\n",
    "    if 5000 <= steps <= 12499: return 'Moderate Active'\n",
    "    return 'Low Active'\n",
    "\n",
    "def bucket_sleep(mins):\n",
    "    if pd.isna(mins): return 'Unknown'\n",
    "    return 'Adequate Sleep' if mins >= 420 else 'Inadequate Sleep'\n",
    "\n",
    "seg = df.copy()\n",
    "seg['activity_level'] = seg['TotalSteps'].apply(bucket_activity)\n",
    "if 'TotalMinutesAsleep' in seg.columns:\n",
    "    seg['sleep_pattern'] = seg['TotalMinutesAsleep'].apply(bucket_sleep)\n",
    "\n",
    "print('Activity levels:')\n",
    "print(seg['activity_level'].value_counts(dropna=False))\n",
    "\n",
    "if 'sleep_pattern' in seg.columns:\n",
    "    print('\\nSleep patterns:')\n",
    "    print(seg['sleep_pattern'].value_counts(dropna=False))\n",
    "\n",
    "# Cross-tab (activity vs sleep)\n",
    "if 'sleep_pattern' in seg.columns:\n",
    "    print('\\nActivity vs Sleep cross-tab:')\n",
    "    print(pd.crosstab(seg['activity_level'], seg['sleep_pattern']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
