{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c3a375",
   "metadata": {},
   "source": [
    "Goal: fetch 5Y standardized statements for peers via OpenDART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb84f6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os,io,zipfile,xml.etree.ElementTree as ET \n",
    "from datetime import datetime\n",
    "import requests,pandas as pd \n",
    "\n",
    "API=\"https://engopendar.fss.or.kr/engapi\"\n",
    "KEY = os.getenv(\"DART_API_KEY)\n",
    "\n",
    "assert KEY and len(key) >= 20. \"Missing DART_API_KEY. Add it to your environment and re-run.\"\n",
    "\n",
    "PEER_TICKERS = [\"278470\", \"090430\",\"051900\"] #APR, Amore Pacific, LG H&H \n",
    "YEARS = list(range(datetime.now().year-4,datetime.now().year+1))\n",
    "REPRT = {\"A\":\"11011\"} #Annual report code\n",
    "STATEMENTS = [\"BS\",\"IS\",\"CF\"] #Balance sheet, Income Statement, Cashflow Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708e7db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_corp_table():\n",
    "    \"\"\"Download corpCode XML (zipped) and return DataFrame of corp_code/stock_code/corp_name.\"\"\"\n",
    "    url = f\"{API}/corpCode.xml\"\n",
    "    r = requests.get(url, params={\"crtfc_key\": KEY}, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as zf:\n",
    "        xml_name = zf.namelist()[0]\n",
    "        xml_bytes = zf.read(xml_name)\n",
    "    root = ET.fromstring(xml_bytes)\n",
    "    rows = []\n",
    "    for el in root.findall(\".//list\"):\n",
    "        rows.append({\n",
    "            \"corp_code\": el.findtext(\"corp_code\"),\n",
    "            \"corp_name\": el.findtext(\"corp_name\"),\n",
    "            \"stock_code\": el.findtext(\"stock_code\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def resolve_by_stock(df, stock_codes):\n",
    "    stock_codes = {str(s).zfill(6) for s in stock_codes}\n",
    "    out = df[df[\"stock_code\"].isin(stock_codes)].copy()\n",
    "    return out[[\"stock_code\", \"corp_name\", \"corp_code\"]].reset_index(drop=True)\n",
    "\n",
    "def fetch_fnltt_singl_all(corp_code, bsns_year, reprt_code, fs_div=\"CFS\", sj_div=None):\n",
    "    \"\"\"Call fnlttSinglAcntAll for one company-year-report. Returns a tidy DataFrame.\"\"\"\n",
    "    params = {\n",
    "        \"crtfc_key\": KEY,\n",
    "        \"corp_code\": corp_code,\n",
    "        \"bsns_year\": str(bsns_year),\n",
    "        \"reprt_code\": reprt_code,\n",
    "        \"fs_div\": fs_div,                   # CFS or OFS\n",
    "    }\n",
    "    if sj_div:\n",
    "        params[\"sj_div\"] = sj_div          # BS/IS/CF\n",
    "    url = f\"{API}/fnlttSinglAcntAll.json\"\n",
    "    r = requests.get(url, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if data.get(\"status\") != \"000\":\n",
    "        # No data / out-of-range year / etc. -> return empty frame\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data.get(\"list\", []))\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Keep relevant columns if present\n",
    "    keep = [\"corp_code\",\"bsns_year\",\"reprt_code\",\"fs_div\",\"sj_div\",\"sj_nm\",\n",
    "            \"account_id\",\"account_nm\",\"thstrm_amount\",\"thstrm_add_amount\",\n",
    "            \"frmtrm_amount\",\"frmtrm_add_amount\",\"bfefrmtrm_amount\",\"currency\"]\n",
    "    df = df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "    # Numeric clean (amounts come as strings with commas)\n",
    "    for c in [\"thstrm_amount\",\"thstrm_add_amount\",\"frmtrm_amount\",\"frmtrm_add_amount\",\"bfefrmtrm_amount\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96d5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corp_df = get_corp_table()\n",
    "peer_map = resolve_by_stock(corp_df, PEER_TICKERS)\n",
    "display(peer_map)  # expect 3 rows with corp_code\n",
    "\n",
    "frames = []\n",
    "for _, row in peer_map.iterrows():\n",
    "    code = row.corp_code\n",
    "    for y in YEARS:\n",
    "        for sj in STATEMENTS:\n",
    "            df = fetch_fnltt_singl_all(code, y, REPRT[\"A\"], fs_div=\"CFS\", sj_div=sj)\n",
    "            if not df.empty:\n",
    "                frames.append(df)\n",
    "\n",
    "peer_raw = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "print(peer_raw.shape)\n",
    "peer_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a51013",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save long-format for downstream use\n",
    "out_dir = \"Projects/kbeauty-device-brief/data/processed\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "peer_raw.to_parquet(f\"{out_dir}/peer_raw.parquet\", index=False)\n",
    "\n",
    "# Build a compact \"wide\" view by company-year\n",
    "# Prefer account_id if present (stable IFRS tags); else fallback to account_nm.\n",
    "def _best_account_col(df):\n",
    "    if \"account_id\" in df and df[\"account_id\"].notna().any():\n",
    "        return \"account_id\"\n",
    "    return \"account_nm\"\n",
    "\n",
    "acct_col = _best_account_col(peer_raw)\n",
    "\n",
    "# Use 'thstrm_amount' (당기) as the annual reported figure.\n",
    "pivot = (peer_raw\n",
    "         .pivot_table(index=[\"corp_code\",\"bsns_year\",\"sj_div\",\"currency\"],\n",
    "                      columns=acct_col, values=\"thstrm_amount\", aggfunc=\"first\")\n",
    "         .reset_index())\n",
    "\n",
    "# Optional: collapse BS/IS/CF into one row per company-year (columns keep prefixes)\n",
    "pivot[\"sj_div\"] = pivot[\"sj_div\"].fillna(\"NA\")\n",
    "wide = (pivot\n",
    "        .assign(idx=pivot[\"corp_code\"].astype(str)+\"_\"+pivot[\"bsns_year\"].astype(str))\n",
    "        .set_index([\"idx\",\"sj_div\"])\n",
    "        .sort_index())\n",
    "\n",
    "# Join BS/IS/CF blocks side-by-side\n",
    "wide_blocks = []\n",
    "for sj in [\"BS\",\"IS\",\"CF\"]:\n",
    "    if (wide.index.get_level_values(\"sj_div\") == sj).any():\n",
    "        block = wide.loc[(slice(None), sj)].droplevel(\"sj_div\")\n",
    "        # add prefix to avoid duplicate column names across statements\n",
    "        block.columns = [f\"{sj}:{c}\" for c in block.columns]\n",
    "        wide_blocks.append(block)\n",
    "\n",
    "peer_wide = pd.concat(wide_blocks, axis=1).reset_index().rename(columns={\"idx\":\"_key\"})\n",
    "# Recover corp_code and year from _key\n",
    "peer_wide[[\"corp_code\",\"bsns_year\"]] = peer_wide[\"_key\"].str.split(\"_\", expand=True)\n",
    "peer_wide.drop(columns=[\"_key\"], inplace=True)\n",
    "peer_wide = peer_wide.sort_values([\"corp_code\",\"bsns_year\"])\n",
    "\n",
    "peer_wide.to_csv(f\"{out_dir}/peer_wide.csv\", index=False)\n",
    "peer_wide.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
